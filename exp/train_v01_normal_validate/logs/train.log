01:30:24,104 root INFO MeanPoolingLinear(
  (hidden_layers): Sequential(
    (0): Linear(in_features=768, out_features=256, bias=True)
  )
  (pooling): MeanPooling()
  (final_proj): Linear(in_features=256, out_features=4, bias=True)
)
01:30:24,105 root INFO Built a model with 0.20M Params
01:30:24,111 root INFO Start to run five fold 1/5
01:30:24,111 root INFO Model initialized
01:30:24,111 root INFO Start to train epoch 0
01:30:37,847 root INFO [Epoch 0, Batch=99] Train: loss=0.3693, lr=0.001
01:30:42,965 root INFO [Epoch 0, Batch=199] Train: loss=0.2417, lr=0.001
01:30:50,855 root INFO [Epoch 0, Batch=299] Train: loss=0.3746, lr=0.001
01:30:54,459 root INFO [Epoch 0, Batch=399] Train: loss=0.3276, lr=0.001
01:32:28,231 root INFO [Epoch 0, Batch=499] Train: loss=0.1350, lr=0.001
01:32:55,986 root INFO [Epoch 0, Batch=599] Train: loss=0.2294, lr=0.001
01:33:02,541 root INFO [Epoch 0, Batch=699] Train: loss=0.2740, lr=0.001
01:33:06,900 root INFO [Epoch 0, Batch=799] Train: loss=0.1467, lr=0.001
01:35:52,625 root INFO [Epoch 0, Batch=99] Train(target): MCCloss=0.1707, lr=0.001
01:35:59,145 root INFO [Epoch 0, Batch=199] Train(target): MCCloss=0.1533, lr=0.001
01:36:01,655 root INFO Start to validate epoch 0
01:36:08,963 root INFO Start to test epoch 0
01:36:10,582 root INFO Epoch 00, lr=0.001 | Train: acc=0.5643 | Val: acc=0.5919 | Test: acc=0.6085 | Time: this epoch 346.47s, elapsed 346.47s
01:36:10,857 root INFO [info] Save model after epoch 0

01:36:10,857 root INFO Best test acc=0.6084558963775635
01:36:10,857 root INFO Start to run five fold 2/5
01:36:10,858 root INFO Model initialized
01:36:10,893 root INFO Start to train epoch 0
01:36:16,427 root INFO [Epoch 0, Batch=99] Train: loss=0.3044, lr=0.001
01:36:21,166 root INFO [Epoch 0, Batch=199] Train: loss=0.2929, lr=0.001
01:36:25,909 root INFO [Epoch 0, Batch=299] Train: loss=0.2345, lr=0.001
01:36:30,542 root INFO [Epoch 0, Batch=399] Train: loss=0.1831, lr=0.001
01:36:34,261 root INFO [Epoch 0, Batch=499] Train: loss=0.5125, lr=0.001
01:36:39,85 root INFO [Epoch 0, Batch=599] Train: loss=0.2553, lr=0.001
01:36:43,671 root INFO [Epoch 0, Batch=699] Train: loss=0.1717, lr=0.001
01:36:47,656 root INFO [Epoch 0, Batch=799] Train: loss=0.2245, lr=0.001
01:36:51,792 root INFO [Epoch 0, Batch=899] Train: loss=0.2034, lr=0.001
01:37:00,249 root INFO [Epoch 0, Batch=99] Train(target): MCCloss=0.1810, lr=0.001
01:37:04,450 root INFO [Epoch 0, Batch=199] Train(target): MCCloss=0.1797, lr=0.001
01:37:08,256 root INFO Start to validate epoch 0
01:37:19,487 root INFO Start to test epoch 0
01:37:21,85 root INFO Epoch 00, lr=0.001 | Train: acc=0.5567 | Val: acc=0.5431 | Test: acc=0.5814 | Time: this epoch 70.19s, elapsed 416.97s
01:37:21,458 root INFO [info] Save model after epoch 0

01:37:21,458 root INFO Best test acc=0.5813801884651184
01:37:21,458 root INFO Start to run five fold 3/5
01:37:21,458 root INFO Model initialized
01:37:21,511 root INFO Start to train epoch 0
01:37:27,280 root INFO [Epoch 0, Batch=99] Train: loss=0.3728, lr=0.001
01:37:32,180 root INFO [Epoch 0, Batch=199] Train: loss=0.3049, lr=0.001
01:37:37,33 root INFO [Epoch 0, Batch=299] Train: loss=0.1729, lr=0.001
01:37:40,419 root INFO [Epoch 0, Batch=399] Train: loss=0.3077, lr=0.001
01:37:43,374 root INFO [Epoch 0, Batch=499] Train: loss=0.3007, lr=0.001
01:37:45,446 root INFO [Epoch 0, Batch=599] Train: loss=0.2980, lr=0.001
01:37:47,318 root INFO [Epoch 0, Batch=699] Train: loss=0.1110, lr=0.001
01:37:48,613 root INFO [Epoch 0, Batch=799] Train: loss=0.2337, lr=0.001
01:37:56,671 root INFO [Epoch 0, Batch=99] Train(target): MCCloss=0.1835, lr=0.001
01:38:00,632 root INFO [Epoch 0, Batch=199] Train(target): MCCloss=0.1724, lr=0.001
01:38:03,770 root INFO Start to validate epoch 0
01:38:15,572 root INFO Start to test epoch 0
01:38:16,992 root INFO Epoch 00, lr=0.001 | Train: acc=0.5576 | Val: acc=0.6153 | Test: acc=0.5590 | Time: this epoch 55.48s, elapsed 472.88s
01:38:17,330 root INFO [info] Save model after epoch 0

01:38:17,330 root INFO Best test acc=0.5590277910232544
01:38:17,330 root INFO Start to run five fold 4/5
01:38:17,330 root INFO Model initialized
01:38:17,350 root INFO Start to train epoch 0
01:38:25,679 root INFO [Epoch 0, Batch=99] Train: loss=0.3475, lr=0.001
01:38:31,169 root INFO [Epoch 0, Batch=199] Train: loss=0.2336, lr=0.001
01:38:35,278 root INFO [Epoch 0, Batch=299] Train: loss=0.3409, lr=0.001
01:38:38,920 root INFO [Epoch 0, Batch=399] Train: loss=0.3079, lr=0.001
01:38:41,678 root INFO [Epoch 0, Batch=499] Train: loss=0.1542, lr=0.001
01:38:44,286 root INFO [Epoch 0, Batch=599] Train: loss=0.3259, lr=0.001
01:38:47,459 root INFO [Epoch 0, Batch=699] Train: loss=0.2136, lr=0.001
01:38:49,879 root INFO [Epoch 0, Batch=799] Train: loss=0.2822, lr=0.001
01:38:52,980 root INFO [Epoch 0, Batch=899] Train: loss=0.1580, lr=0.001
01:39:00,273 root INFO [Epoch 0, Batch=99] Train(target): MCCloss=0.1772, lr=0.001
01:39:04,97 root INFO [Epoch 0, Batch=199] Train(target): MCCloss=0.1745, lr=0.001
01:39:07,297 root INFO Start to validate epoch 0
01:39:17,562 root INFO Start to test epoch 0
01:39:18,702 root INFO Epoch 00, lr=0.001 | Train: acc=0.5483 | Val: acc=0.5785 | Test: acc=0.5446 | Time: this epoch 61.35s, elapsed 534.59s
01:39:19,301 root INFO [info] Save model after epoch 0

01:39:19,302 root INFO Best test acc=0.5445736646652222
01:39:19,302 root INFO Start to run five fold 5/5
01:39:19,302 root INFO Model initialized
01:39:19,372 root INFO Start to train epoch 0
01:39:25,61 root INFO [Epoch 0, Batch=99] Train: loss=0.4095, lr=0.001
01:39:30,442 root INFO [Epoch 0, Batch=199] Train: loss=0.2901, lr=0.001
01:39:36,242 root INFO [Epoch 0, Batch=299] Train: loss=0.2598, lr=0.001
01:39:39,568 root INFO [Epoch 0, Batch=399] Train: loss=0.2761, lr=0.001
01:39:40,847 root INFO [Epoch 0, Batch=499] Train: loss=0.1493, lr=0.001
01:39:41,639 root INFO [Epoch 0, Batch=599] Train: loss=0.1806, lr=0.001
01:39:42,212 root INFO [Epoch 0, Batch=699] Train: loss=0.2250, lr=0.001
01:39:42,439 root INFO [Epoch 0, Batch=799] Train: loss=0.1460, lr=0.001
01:39:48,151 root INFO [Epoch 0, Batch=99] Train(target): MCCloss=0.1733, lr=0.001
01:39:48,441 root INFO [Epoch 0, Batch=199] Train(target): MCCloss=0.1629, lr=0.001
01:39:48,680 root INFO [Epoch 0, Batch=299] Train(target): MCCloss=0.1772, lr=0.001
01:39:48,741 root INFO Start to validate epoch 0
01:39:49,356 root INFO Start to test epoch 0
01:39:50,471 root INFO Epoch 00, lr=0.001 | Train: acc=0.5463 | Val: acc=0.5663 | Test: acc=0.5297 | Time: this epoch 31.10s, elapsed 566.36s
01:39:50,480 root INFO [info] Save model after epoch 0

01:39:50,480 root INFO Best test acc=0.5297427773475647
01:39:50,480 root INFO five fold acc: 0.5646360516548157
01:48:14,153 root INFO MeanPoolingLinear(
  (hidden_layers): Sequential(
    (0): Linear(in_features=768, out_features=256, bias=True)
  )
  (pooling): MeanPooling()
  (final_proj): Linear(in_features=256, out_features=4, bias=True)
)
01:48:14,154 root INFO Built a model with 0.20M Params
01:48:14,158 root INFO Start to run five fold 1/5
01:48:14,159 root INFO Model initialized
01:48:14,159 root INFO Start to train epoch 0
01:48:54,734 root INFO MeanPoolingLinear(
  (hidden_layers): Sequential(
    (0): Linear(in_features=768, out_features=256, bias=True)
  )
  (pooling): MeanPooling()
  (final_proj): Linear(in_features=256, out_features=4, bias=True)
)
01:48:54,734 root INFO Built a model with 0.20M Params
01:48:54,738 root INFO Start to run five fold 1/5
01:48:54,738 root INFO Model initialized
01:48:54,738 root INFO Start to train epoch 0
01:50:42,735 root INFO MeanPoolingLinear(
  (hidden_layers): Sequential(
    (0): Linear(in_features=768, out_features=256, bias=True)
  )
  (pooling): MeanPooling()
  (final_proj): Linear(in_features=256, out_features=4, bias=True)
)
01:50:42,735 root INFO Built a model with 0.20M Params
01:50:42,740 root INFO Start to run five fold 1/5
01:50:42,740 root INFO Model initialized
01:50:42,740 root INFO Start to train epoch 0
01:51:01,463 root INFO MeanPoolingLinear(
  (hidden_layers): Sequential(
    (0): Linear(in_features=768, out_features=256, bias=True)
  )
  (pooling): MeanPooling()
  (final_proj): Linear(in_features=256, out_features=4, bias=True)
)
01:51:01,464 root INFO Built a model with 0.20M Params
01:51:01,468 root INFO Start to run five fold 1/5
01:51:01,468 root INFO Model initialized
01:51:01,468 root INFO Start to train epoch 0
01:53:00,791 root INFO MeanPoolingLinear(
  (hidden_layers): Sequential(
    (0): Linear(in_features=768, out_features=256, bias=True)
  )
  (pooling): MeanPooling()
  (final_proj): Linear(in_features=256, out_features=4, bias=True)
)
01:53:00,791 root INFO Built a model with 0.20M Params
01:53:00,796 root INFO Start to run five fold 1/5
01:53:00,796 root INFO Model initialized
01:53:00,796 root INFO Start to train epoch 0
01:53:05,327 root INFO [Epoch 0, Batch=99] Train: loss=0.3675, lr=0.001
01:53:06,564 root INFO [Epoch 0, Batch=199] Train: loss=0.3611, lr=0.001
01:53:07,299 root INFO [Epoch 0, Batch=299] Train: loss=0.2990, lr=0.001
01:53:07,860 root INFO [Epoch 0, Batch=399] Train: loss=0.0670, lr=0.001
01:53:08,390 root INFO [Epoch 0, Batch=499] Train: loss=0.1841, lr=0.001
01:53:09,3 root INFO [Epoch 0, Batch=599] Train: loss=0.2248, lr=0.001
01:53:09,509 root INFO [Epoch 0, Batch=699] Train: loss=0.3032, lr=0.001
01:53:10,830 root INFO [Epoch 0, Batch=799] Train: loss=0.0531, lr=0.001
01:53:11,414 root INFO [Epoch 0, Batch=899] Train: loss=0.3109, lr=0.001
01:53:12,41 root INFO [Epoch 0, Batch=999] Train: loss=0.2980, lr=0.001
01:53:12,487 root INFO [Epoch 0, Batch=1099] Train: loss=0.3201, lr=0.001
01:53:13,92 root INFO [Epoch 0, Batch=1199] Train: loss=0.1898, lr=0.001
01:53:13,871 root INFO [Epoch 0, Batch=1299] Train: loss=0.1101, lr=0.001
01:53:14,450 root INFO [Epoch 0, Batch=1399] Train: loss=0.1532, lr=0.001
01:53:15,64 root INFO [Epoch 0, Batch=1499] Train: loss=0.1470, lr=0.001
01:53:15,589 root INFO [Epoch 0, Batch=1599] Train: loss=0.1655, lr=0.001
01:53:15,998 root INFO [Epoch 0, Batch=1699] Train: loss=0.1045, lr=0.001
01:53:16,415 root INFO [Epoch 0, Batch=1799] Train: loss=0.3281, lr=0.001
01:53:17,5 root INFO [Epoch 0, Batch=1899] Train: loss=0.1027, lr=0.001
01:53:18,55 root INFO [Epoch 0, Batch=1999] Train: loss=0.0618, lr=0.001
01:53:18,567 root INFO [Epoch 0, Batch=2099] Train: loss=0.3292, lr=0.001
01:53:19,40 root INFO [Epoch 0, Batch=2199] Train: loss=0.3781, lr=0.001
01:53:19,653 root INFO [Epoch 0, Batch=2299] Train: loss=0.3365, lr=0.001
01:53:20,161 root INFO [Epoch 0, Batch=2399] Train: loss=0.1122, lr=0.001
01:53:20,668 root INFO [Epoch 0, Batch=2499] Train: loss=0.4542, lr=0.001
01:53:21,197 root INFO [Epoch 0, Batch=2599] Train: loss=0.1012, lr=0.001
01:53:21,927 root INFO [Epoch 0, Batch=2699] Train: loss=0.1836, lr=0.001
01:53:22,639 root INFO [Epoch 0, Batch=2799] Train: loss=0.2697, lr=0.001
01:53:23,318 root INFO [Epoch 0, Batch=2899] Train: loss=0.0314, lr=0.001
01:53:23,997 root INFO [Epoch 0, Batch=2999] Train: loss=0.3086, lr=0.001
01:53:24,642 root INFO [Epoch 0, Batch=3099] Train: loss=0.2379, lr=0.001
01:53:25,404 root INFO [Epoch 0, Batch=3199] Train: loss=0.3029, lr=0.001
01:53:26,247 root INFO [Epoch 0, Batch=3299] Train: loss=0.1021, lr=0.001
01:53:26,893 root INFO [Epoch 0, Batch=3399] Train: loss=0.1838, lr=0.001
01:53:27,691 root INFO [Epoch 0, Batch=3499] Train: loss=0.3013, lr=0.001
01:53:29,888 root INFO [Epoch 0, Batch=99] Train(target): MCCloss=0.1875, lr=0.001
01:53:31,695 root INFO [Epoch 0, Batch=199] Train(target): MCCloss=0.1875, lr=0.001
01:53:33,344 root INFO [Epoch 0, Batch=299] Train(target): MCCloss=0.1875, lr=0.001
01:53:35,292 root INFO [Epoch 0, Batch=399] Train(target): MCCloss=0.1875, lr=0.001
01:53:36,739 root INFO [Epoch 0, Batch=499] Train(target): MCCloss=0.1875, lr=0.001
01:53:37,931 root INFO [Epoch 0, Batch=599] Train(target): MCCloss=0.1875, lr=0.001
01:53:39,363 root INFO [Epoch 0, Batch=699] Train(target): MCCloss=0.1875, lr=0.001
01:53:40,328 root INFO [Epoch 0, Batch=799] Train(target): MCCloss=0.1875, lr=0.001
01:53:41,297 root INFO [Epoch 0, Batch=899] Train(target): MCCloss=0.1875, lr=0.001
01:53:42,889 root INFO [Epoch 0, Batch=999] Train(target): MCCloss=0.1875, lr=0.001
01:53:45,271 root INFO Start to validate epoch 0
01:54:02,373 root INFO Start to test epoch 0
01:54:07,15 root INFO Epoch 00, lr=0.001 | Train: acc=0.5846 | Val: acc=0.6584 | Test: acc=0.5899 | Time: this epoch 66.22s, elapsed 66.22s
01:54:07,367 root INFO [info] Save model after epoch 0

01:54:07,367 root INFO Best test acc=0.5898617506027222
01:54:07,367 root INFO Start to run five fold 2/5
01:54:07,367 root INFO Model initialized
01:54:07,432 root INFO Start to train epoch 0
01:54:08,588 root INFO [Epoch 0, Batch=99] Train: loss=0.3961, lr=0.001
01:54:09,4 root INFO [Epoch 0, Batch=199] Train: loss=0.2635, lr=0.001
01:54:09,363 root INFO [Epoch 0, Batch=299] Train: loss=0.0977, lr=0.001
01:54:09,886 root INFO [Epoch 0, Batch=399] Train: loss=0.1071, lr=0.001
01:54:10,537 root INFO [Epoch 0, Batch=499] Train: loss=0.3095, lr=0.001
01:54:10,911 root INFO [Epoch 0, Batch=599] Train: loss=0.1023, lr=0.001
01:54:11,476 root INFO [Epoch 0, Batch=699] Train: loss=0.1563, lr=0.001
01:54:12,55 root INFO [Epoch 0, Batch=799] Train: loss=0.8066, lr=0.001
01:54:12,470 root INFO [Epoch 0, Batch=899] Train: loss=0.4137, lr=0.001
01:54:12,963 root INFO [Epoch 0, Batch=999] Train: loss=0.0841, lr=0.001
01:54:13,394 root INFO [Epoch 0, Batch=1099] Train: loss=0.0331, lr=0.001
01:54:14,51 root INFO [Epoch 0, Batch=1199] Train: loss=0.1671, lr=0.001
01:54:14,625 root INFO [Epoch 0, Batch=1299] Train: loss=0.1816, lr=0.001
01:54:15,321 root INFO [Epoch 0, Batch=1399] Train: loss=0.1318, lr=0.001
01:54:15,848 root INFO [Epoch 0, Batch=1499] Train: loss=0.1621, lr=0.001
01:54:16,273 root INFO [Epoch 0, Batch=1599] Train: loss=0.2762, lr=0.001
01:54:16,730 root INFO [Epoch 0, Batch=1699] Train: loss=0.4941, lr=0.001
01:54:17,248 root INFO [Epoch 0, Batch=1799] Train: loss=0.1448, lr=0.001
01:54:18,19 root INFO [Epoch 0, Batch=1899] Train: loss=0.2450, lr=0.001
01:54:18,683 root INFO [Epoch 0, Batch=1999] Train: loss=0.2690, lr=0.001
01:54:19,352 root INFO [Epoch 0, Batch=2099] Train: loss=0.0834, lr=0.001
01:54:20,3 root INFO [Epoch 0, Batch=2199] Train: loss=0.3711, lr=0.001
01:54:20,511 root INFO [Epoch 0, Batch=2299] Train: loss=0.2853, lr=0.001
01:54:21,175 root INFO [Epoch 0, Batch=2399] Train: loss=0.0758, lr=0.001
01:54:21,944 root INFO [Epoch 0, Batch=2499] Train: loss=0.7519, lr=0.001
01:54:22,594 root INFO [Epoch 0, Batch=2599] Train: loss=0.0393, lr=0.001
01:54:23,316 root INFO [Epoch 0, Batch=2699] Train: loss=0.4586, lr=0.001
01:54:23,978 root INFO [Epoch 0, Batch=2799] Train: loss=0.0987, lr=0.001
01:54:24,708 root INFO [Epoch 0, Batch=2899] Train: loss=0.3661, lr=0.001
01:54:25,415 root INFO [Epoch 0, Batch=2999] Train: loss=0.2081, lr=0.001
01:54:26,614 root INFO [Epoch 0, Batch=3099] Train: loss=0.6346, lr=0.001
01:54:27,350 root INFO [Epoch 0, Batch=3199] Train: loss=0.4792, lr=0.001
01:54:28,185 root INFO [Epoch 0, Batch=3299] Train: loss=0.0033, lr=0.001
01:54:29,7 root INFO [Epoch 0, Batch=3399] Train: loss=0.5306, lr=0.001
01:54:30,409 root INFO [Epoch 0, Batch=3499] Train: loss=0.0634, lr=0.001
01:54:31,580 root INFO [Epoch 0, Batch=3599] Train: loss=0.0021, lr=0.001
01:54:33,440 root INFO [Epoch 0, Batch=99] Train(target): MCCloss=0.1875, lr=0.001
01:54:35,558 root INFO [Epoch 0, Batch=199] Train(target): MCCloss=0.1875, lr=0.001
01:54:36,668 root INFO [Epoch 0, Batch=299] Train(target): MCCloss=0.1875, lr=0.001
01:54:37,937 root INFO [Epoch 0, Batch=399] Train(target): MCCloss=0.1875, lr=0.001
01:54:39,223 root INFO [Epoch 0, Batch=499] Train(target): MCCloss=0.1875, lr=0.001
01:54:40,325 root INFO [Epoch 0, Batch=599] Train(target): MCCloss=0.1875, lr=0.001
01:54:41,390 root INFO [Epoch 0, Batch=699] Train(target): MCCloss=0.1875, lr=0.001
01:54:42,888 root INFO [Epoch 0, Batch=799] Train(target): MCCloss=0.1875, lr=0.001
01:54:44,5 root INFO [Epoch 0, Batch=899] Train(target): MCCloss=0.1875, lr=0.001
01:54:45,189 root INFO [Epoch 0, Batch=999] Train(target): MCCloss=0.1875, lr=0.001
01:54:45,448 root INFO Start to validate epoch 0
01:54:59,742 root INFO Start to test epoch 0
01:55:01,778 root INFO Epoch 00, lr=0.001 | Train: acc=0.5843 | Val: acc=0.6552 | Test: acc=0.6442 | Time: this epoch 54.35s, elapsed 120.98s
01:55:02,90 root INFO [info] Save model after epoch 0

01:55:02,90 root INFO Best test acc=0.6441837549209595
01:55:02,91 root INFO Start to run five fold 3/5
01:55:02,91 root INFO Model initialized
01:55:02,91 root INFO Start to train epoch 0
01:55:02,684 root INFO [Epoch 0, Batch=99] Train: loss=0.4133, lr=0.001
01:55:03,609 root INFO [Epoch 0, Batch=199] Train: loss=0.4150, lr=0.001
01:55:04,26 root INFO [Epoch 0, Batch=299] Train: loss=0.3758, lr=0.001
01:55:04,555 root INFO [Epoch 0, Batch=399] Train: loss=0.2014, lr=0.001
01:55:05,169 root INFO [Epoch 0, Batch=499] Train: loss=0.1255, lr=0.001
01:55:06,364 root INFO [Epoch 0, Batch=599] Train: loss=0.1367, lr=0.001
01:55:07,18 root INFO [Epoch 0, Batch=699] Train: loss=0.1198, lr=0.001
01:55:07,708 root INFO [Epoch 0, Batch=799] Train: loss=0.1446, lr=0.001
01:55:08,285 root INFO [Epoch 0, Batch=899] Train: loss=0.0603, lr=0.001
01:55:09,79 root INFO [Epoch 0, Batch=999] Train: loss=0.6887, lr=0.001
01:55:09,828 root INFO [Epoch 0, Batch=1099] Train: loss=0.7764, lr=0.001
01:55:10,287 root INFO [Epoch 0, Batch=1199] Train: loss=0.3267, lr=0.001
01:55:11,97 root INFO [Epoch 0, Batch=1299] Train: loss=0.2733, lr=0.001
01:55:11,637 root INFO [Epoch 0, Batch=1399] Train: loss=0.0391, lr=0.001
01:55:12,266 root INFO [Epoch 0, Batch=1499] Train: loss=0.1822, lr=0.001
01:55:12,804 root INFO [Epoch 0, Batch=1599] Train: loss=0.4086, lr=0.001
01:55:13,301 root INFO [Epoch 0, Batch=1699] Train: loss=0.0485, lr=0.001
01:55:13,860 root INFO [Epoch 0, Batch=1799] Train: loss=0.1430, lr=0.001
01:55:14,754 root INFO [Epoch 0, Batch=1899] Train: loss=0.1861, lr=0.001
01:55:15,699 root INFO [Epoch 0, Batch=1999] Train: loss=0.6275, lr=0.001
01:55:16,273 root INFO [Epoch 0, Batch=2099] Train: loss=0.0598, lr=0.001
01:55:16,920 root INFO [Epoch 0, Batch=2199] Train: loss=0.0210, lr=0.001
01:55:17,678 root INFO [Epoch 0, Batch=2299] Train: loss=0.5387, lr=0.001
01:55:18,344 root INFO [Epoch 0, Batch=2399] Train: loss=0.0682, lr=0.001
01:55:19,97 root INFO [Epoch 0, Batch=2499] Train: loss=0.1921, lr=0.001
01:55:20,20 root INFO [Epoch 0, Batch=2599] Train: loss=0.1044, lr=0.001
01:55:20,710 root INFO [Epoch 0, Batch=2699] Train: loss=0.7098, lr=0.001
01:55:21,391 root INFO [Epoch 0, Batch=2799] Train: loss=0.3553, lr=0.001
01:55:22,424 root INFO [Epoch 0, Batch=2899] Train: loss=0.0210, lr=0.001
01:55:23,569 root INFO [Epoch 0, Batch=2999] Train: loss=0.0850, lr=0.001
01:55:24,283 root INFO [Epoch 0, Batch=3099] Train: loss=1.2132, lr=0.001
01:55:26,419 root INFO [Epoch 0, Batch=3199] Train: loss=0.1188, lr=0.001
01:55:27,338 root INFO [Epoch 0, Batch=3299] Train: loss=0.0769, lr=0.001
01:55:28,273 root INFO [Epoch 0, Batch=3399] Train: loss=0.3294, lr=0.001
01:55:29,174 root INFO [Epoch 0, Batch=3499] Train: loss=0.0731, lr=0.001
01:55:31,103 root INFO [Epoch 0, Batch=99] Train(target): MCCloss=0.1875, lr=0.001
01:55:32,480 root INFO [Epoch 0, Batch=199] Train(target): MCCloss=0.1875, lr=0.001
01:55:33,495 root INFO [Epoch 0, Batch=299] Train(target): MCCloss=0.1875, lr=0.001
01:55:35,797 root INFO [Epoch 0, Batch=399] Train(target): MCCloss=0.1875, lr=0.001
01:55:39,148 root INFO [Epoch 0, Batch=499] Train(target): MCCloss=0.1875, lr=0.001
01:55:40,232 root INFO [Epoch 0, Batch=599] Train(target): MCCloss=0.1875, lr=0.001
01:55:41,286 root INFO [Epoch 0, Batch=699] Train(target): MCCloss=0.1875, lr=0.001
01:55:43,1 root INFO [Epoch 0, Batch=799] Train(target): MCCloss=0.1875, lr=0.001
01:55:44,97 root INFO [Epoch 0, Batch=899] Train(target): MCCloss=0.1875, lr=0.001
01:55:44,883 root INFO [Epoch 0, Batch=999] Train(target): MCCloss=0.1875, lr=0.001
01:55:46,155 root INFO [Epoch 0, Batch=1099] Train(target): MCCloss=0.1875, lr=0.001
01:55:46,663 root INFO Start to validate epoch 0
01:56:00,864 root INFO Start to test epoch 0
01:56:03,324 root INFO Epoch 00, lr=0.001 | Train: acc=0.5893 | Val: acc=0.6541 | Test: acc=0.6308 | Time: this epoch 61.23s, elapsed 182.53s
01:56:03,890 root INFO [info] Save model after epoch 0

01:56:03,890 root INFO Best test acc=0.6307559013366699
01:56:03,891 root INFO Start to run five fold 4/5
01:56:03,891 root INFO Model initialized
01:56:04,24 root INFO Start to train epoch 0
01:56:04,539 root INFO [Epoch 0, Batch=99] Train: loss=0.1867, lr=0.001
01:56:05,22 root INFO [Epoch 0, Batch=199] Train: loss=0.2795, lr=0.001
01:56:05,771 root INFO [Epoch 0, Batch=299] Train: loss=0.3210, lr=0.001
01:56:06,171 root INFO [Epoch 0, Batch=399] Train: loss=0.2457, lr=0.001
01:56:06,666 root INFO [Epoch 0, Batch=499] Train: loss=0.5770, lr=0.001
01:56:07,114 root INFO [Epoch 0, Batch=599] Train: loss=0.1582, lr=0.001
01:56:07,522 root INFO [Epoch 0, Batch=699] Train: loss=0.4216, lr=0.001
01:56:08,28 root INFO [Epoch 0, Batch=799] Train: loss=0.5552, lr=0.001
01:56:08,487 root INFO [Epoch 0, Batch=899] Train: loss=0.2186, lr=0.001
01:56:08,958 root INFO [Epoch 0, Batch=999] Train: loss=0.3208, lr=0.001
01:56:09,517 root INFO [Epoch 0, Batch=1099] Train: loss=0.1745, lr=0.001
01:56:10,297 root INFO [Epoch 0, Batch=1199] Train: loss=0.2937, lr=0.001
01:56:10,841 root INFO [Epoch 0, Batch=1299] Train: loss=0.2570, lr=0.001
01:56:11,778 root INFO [Epoch 0, Batch=1399] Train: loss=0.1693, lr=0.001
01:56:12,270 root INFO [Epoch 0, Batch=1499] Train: loss=0.2509, lr=0.001
01:56:12,789 root INFO [Epoch 0, Batch=1599] Train: loss=0.1374, lr=0.001
01:56:13,465 root INFO [Epoch 0, Batch=1699] Train: loss=0.1424, lr=0.001
01:56:13,973 root INFO [Epoch 0, Batch=1799] Train: loss=0.1515, lr=0.001
01:56:14,356 root INFO [Epoch 0, Batch=1899] Train: loss=0.2044, lr=0.001
01:56:14,992 root INFO [Epoch 0, Batch=1999] Train: loss=0.1310, lr=0.001
01:56:15,582 root INFO [Epoch 0, Batch=2099] Train: loss=0.1972, lr=0.001
01:56:16,199 root INFO [Epoch 0, Batch=2199] Train: loss=0.1567, lr=0.001
01:56:16,982 root INFO [Epoch 0, Batch=2299] Train: loss=0.3233, lr=0.001
01:56:17,879 root INFO [Epoch 0, Batch=2399] Train: loss=0.1614, lr=0.001
01:56:18,439 root INFO [Epoch 0, Batch=2499] Train: loss=0.7997, lr=0.001
01:56:18,927 root INFO [Epoch 0, Batch=2599] Train: loss=0.1407, lr=0.001
01:56:19,666 root INFO [Epoch 0, Batch=2699] Train: loss=0.2745, lr=0.001
01:56:20,261 root INFO [Epoch 0, Batch=2799] Train: loss=0.5104, lr=0.001
01:56:20,917 root INFO [Epoch 0, Batch=2899] Train: loss=0.0089, lr=0.001
01:56:22,237 root INFO [Epoch 0, Batch=2999] Train: loss=0.0260, lr=0.001
01:56:22,928 root INFO [Epoch 0, Batch=3099] Train: loss=0.8620, lr=0.001
01:56:23,835 root INFO [Epoch 0, Batch=3199] Train: loss=0.0615, lr=0.001
01:56:24,578 root INFO [Epoch 0, Batch=3299] Train: loss=0.3313, lr=0.001
01:56:25,345 root INFO [Epoch 0, Batch=3399] Train: loss=0.0718, lr=0.001
01:56:26,831 root INFO [Epoch 0, Batch=3499] Train: loss=0.0084, lr=0.001
01:56:27,534 root INFO [Epoch 0, Batch=3599] Train: loss=0.0691, lr=0.001
01:56:28,650 root INFO [Epoch 0, Batch=99] Train(target): MCCloss=0.1875, lr=0.001
01:56:31,960 root INFO [Epoch 0, Batch=199] Train(target): MCCloss=0.1875, lr=0.001
01:56:33,43 root INFO [Epoch 0, Batch=299] Train(target): MCCloss=0.1875, lr=0.001
01:56:34,505 root INFO [Epoch 0, Batch=399] Train(target): MCCloss=0.1875, lr=0.001
01:56:36,152 root INFO [Epoch 0, Batch=499] Train(target): MCCloss=0.1875, lr=0.001
01:56:37,908 root INFO [Epoch 0, Batch=599] Train(target): MCCloss=0.1875, lr=0.001
01:56:38,849 root INFO [Epoch 0, Batch=699] Train(target): MCCloss=0.1875, lr=0.001
01:56:39,850 root INFO [Epoch 0, Batch=799] Train(target): MCCloss=0.1875, lr=0.001
01:56:40,972 root INFO [Epoch 0, Batch=899] Train(target): MCCloss=0.1875, lr=0.001
01:56:42,215 root INFO [Epoch 0, Batch=999] Train(target): MCCloss=0.1875, lr=0.001
01:56:42,646 root INFO Start to validate epoch 0
01:56:57,106 root INFO Start to test epoch 0
01:56:59,440 root INFO Epoch 00, lr=0.001 | Train: acc=0.5856 | Val: acc=0.5767 | Test: acc=0.5344 | Time: this epoch 55.42s, elapsed 238.64s
01:56:59,917 root INFO [info] Save model after epoch 0

01:56:59,918 root INFO Best test acc=0.534432590007782
01:56:59,918 root INFO Start to run five fold 5/5
01:56:59,918 root INFO Model initialized
01:56:59,952 root INFO Start to train epoch 0
01:57:00,528 root INFO [Epoch 0, Batch=99] Train: loss=0.4720, lr=0.001
01:57:01,52 root INFO [Epoch 0, Batch=199] Train: loss=0.2918, lr=0.001
01:57:01,866 root INFO [Epoch 0, Batch=299] Train: loss=0.2992, lr=0.001
01:57:02,378 root INFO [Epoch 0, Batch=399] Train: loss=0.0118, lr=0.001
01:57:03,415 root INFO [Epoch 0, Batch=499] Train: loss=0.6463, lr=0.001
01:57:04,87 root INFO [Epoch 0, Batch=599] Train: loss=0.5153, lr=0.001
01:57:04,557 root INFO [Epoch 0, Batch=699] Train: loss=0.1477, lr=0.001
01:57:05,140 root INFO [Epoch 0, Batch=799] Train: loss=0.2159, lr=0.001
01:57:05,925 root INFO [Epoch 0, Batch=899] Train: loss=0.3073, lr=0.001
01:57:06,478 root INFO [Epoch 0, Batch=999] Train: loss=0.1480, lr=0.001
01:57:07,285 root INFO [Epoch 0, Batch=1099] Train: loss=0.1834, lr=0.001
01:57:07,786 root INFO [Epoch 0, Batch=1199] Train: loss=0.0691, lr=0.001
01:57:08,236 root INFO [Epoch 0, Batch=1299] Train: loss=0.2232, lr=0.001
01:57:08,805 root INFO [Epoch 0, Batch=1399] Train: loss=0.1043, lr=0.001
01:57:09,285 root INFO [Epoch 0, Batch=1499] Train: loss=0.2512, lr=0.001
01:57:09,849 root INFO [Epoch 0, Batch=1599] Train: loss=0.0986, lr=0.001
01:57:10,454 root INFO [Epoch 0, Batch=1699] Train: loss=0.2413, lr=0.001
01:57:11,278 root INFO [Epoch 0, Batch=1799] Train: loss=0.2682, lr=0.001
01:57:12,255 root INFO [Epoch 0, Batch=1899] Train: loss=0.0950, lr=0.001
01:57:12,871 root INFO [Epoch 0, Batch=1999] Train: loss=0.1698, lr=0.001
01:57:13,371 root INFO [Epoch 0, Batch=2099] Train: loss=0.3290, lr=0.001
01:57:14,242 root INFO [Epoch 0, Batch=2199] Train: loss=0.3272, lr=0.001
01:57:15,119 root INFO [Epoch 0, Batch=2299] Train: loss=0.0654, lr=0.001
01:57:15,816 root INFO [Epoch 0, Batch=2399] Train: loss=0.3730, lr=0.001
01:57:16,436 root INFO [Epoch 0, Batch=2499] Train: loss=0.3770, lr=0.001
01:57:17,135 root INFO [Epoch 0, Batch=2599] Train: loss=0.0496, lr=0.001
01:57:17,847 root INFO [Epoch 0, Batch=2699] Train: loss=0.1083, lr=0.001
01:57:18,658 root INFO [Epoch 0, Batch=2799] Train: loss=0.7775, lr=0.001
01:57:19,134 root INFO [Epoch 0, Batch=2899] Train: loss=0.0238, lr=0.001
01:57:19,821 root INFO [Epoch 0, Batch=2999] Train: loss=0.6848, lr=0.001
01:57:20,442 root INFO [Epoch 0, Batch=3099] Train: loss=0.0722, lr=0.001
01:57:21,167 root INFO [Epoch 0, Batch=3199] Train: loss=0.0693, lr=0.001
01:57:22,83 root INFO [Epoch 0, Batch=3299] Train: loss=0.3496, lr=0.001
01:57:22,829 root INFO [Epoch 0, Batch=3399] Train: loss=0.3249, lr=0.001
01:57:24,258 root INFO [Epoch 0, Batch=99] Train(target): MCCloss=0.1875, lr=0.001
01:57:25,271 root INFO [Epoch 0, Batch=199] Train(target): MCCloss=0.1875, lr=0.001
01:57:27,568 root INFO [Epoch 0, Batch=299] Train(target): MCCloss=0.1875, lr=0.001
01:57:29,151 root INFO [Epoch 0, Batch=399] Train(target): MCCloss=0.1875, lr=0.001
01:57:31,158 root INFO [Epoch 0, Batch=499] Train(target): MCCloss=0.1875, lr=0.001
01:57:32,104 root INFO [Epoch 0, Batch=599] Train(target): MCCloss=0.1875, lr=0.001
01:57:33,106 root INFO [Epoch 0, Batch=699] Train(target): MCCloss=0.1875, lr=0.001
01:57:34,319 root INFO [Epoch 0, Batch=799] Train(target): MCCloss=0.1875, lr=0.001
01:57:35,859 root INFO [Epoch 0, Batch=899] Train(target): MCCloss=0.1875, lr=0.001
01:57:38,314 root INFO [Epoch 0, Batch=999] Train(target): MCCloss=0.1875, lr=0.001
01:57:39,151 root INFO [Epoch 0, Batch=1099] Train(target): MCCloss=0.1875, lr=0.001
01:57:40,359 root INFO [Epoch 0, Batch=1199] Train(target): MCCloss=0.1875, lr=0.001
01:57:41,805 root INFO Start to validate epoch 0
01:57:57,0 root INFO Start to test epoch 0
01:58:00,90 root INFO Epoch 00, lr=0.001 | Train: acc=0.5860 | Val: acc=0.6573 | Test: acc=0.5866 | Time: this epoch 60.14s, elapsed 299.29s
01:58:00,553 root INFO [info] Save model after epoch 0

01:58:00,553 root INFO Best test acc=0.5866236686706543
01:58:00,553 root INFO five fold acc: 0.5971715450286865
